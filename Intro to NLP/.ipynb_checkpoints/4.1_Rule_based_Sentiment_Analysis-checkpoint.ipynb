{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f48e7f-52dd-434b-a5f6-9025dba265d0",
   "metadata": {},
   "source": [
    "There is no machine learning. It mainly use rules identifying which words associate wtih which sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4434b-084c-4934-8d87-e62547270ae1",
   "metadata": {},
   "source": [
    "TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094369b0-5de2-4031-9420-b4db7b105fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"I finally finished my project, and it turned out even better than I expected.\"\n",
    "sentence2 = \"The app keeps crashing, and it’s really frustrating to use\"\n",
    "sentence3 = \"The meeting is scheduled for 3 p.m. tomorrow.\"\n",
    "sentence4 = \"The food was delicious, but the service was painfully slow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb0e697-6df0-4403-95b2-a230268ddd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15036477-289e-467f-b7ee-3b1e73790d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I finally finished my project, and it turned out even better than I expected.\n",
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentiment_score1 = TextBlob(sentence1)\n",
    "print(sentiment_score1)\n",
    "print(sentiment_score1.sentiment.polarity)\n",
    "#Anything above a 0 is positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1d6725-9983-4b2d-ba03-9b912ada0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The app keeps crashing, and it’s really frustrating to use\n",
      "-0.4\n"
     ]
    }
   ],
   "source": [
    "sentiment_score2 = TextBlob(sentence2)\n",
    "print(sentiment_score2)\n",
    "print(sentiment_score2.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c78f518-ef88-4d0d-8939-79f90c86f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food was delicious, but the service was painfully slow.\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "sentiment_score4 = TextBlob(sentence4)\n",
    "print(sentiment_score4)\n",
    "print(sentiment_score4.sentiment.polarity)\n",
    "#Suppose to be mutual, but there is a positive word \"delicious\" and negative for \"painfully slow\". Trully mutual shows no signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8664ba7-e668-4e54-b98c-0eb1f70cc812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac7a5946-c104-42cc-ad7c-1f2db3a6f2a8",
   "metadata": {},
   "source": [
    "Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f165419c-5575-427c-b712-c1aad390183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6844e491-e9fd-4634-8b69-1fd2a449199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_Sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ec3bb8-9c94-46ef-86ff-8193eb0fab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I finally finished my project, and it turned out even better than I expected.\n",
      "{'neg': 0.0, 'neu': 0.818, 'pos': 0.182, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "print(sentence1)\n",
    "print(vader_Sentiment.polarity_scores(sentence1))\n",
    "# for vader, there is a score for each sentiment, then there is compound score, which is overall which means this is a positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4114d24e-e826-43b2-bca5-f8a9e944469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The app keeps crashing, and it’s really frustrating to use\n",
      "{'neg': 0.262, 'neu': 0.738, 'pos': 0.0, 'compound': -0.4927}\n"
     ]
    }
   ],
   "source": [
    "print(sentence2)\n",
    "print(vader_Sentiment.polarity_scores(sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65997d-001a-4e7a-9617-3aff93d9b307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2808d5af-468d-4409-b169-5813d72ce906",
   "metadata": {},
   "source": [
    "Pre-trained Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dced232-97d0-48f9-9159-a3db506c1bc0",
   "metadata": {},
   "source": [
    "Instead of sequential processing method where the model relies on the previous word for hints about the next, transformers are able to analyze the entire sentence simultaneously to understand the full context and the relationships between multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a467892-5d92-428f-a8ac-56193342350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c95df27-7766-4e4b-808f-de412fa57892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a001dfaf-0dab-403d-ab68-99eb26f3b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c1f0b9dbf84709a5eac0dc0f9f0382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tle72\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tle72\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3543942077e40468556ae2261730c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b3c04e49a14e86b74876ca98e7f390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\") # need to download tensorflow or pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91f1384-c10a-4238-9d6d-b83e32ec6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I finally finished my project, and it turned out even better than I expected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996370077133179}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence1)\n",
    "sentiment_pipeline(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2044918e-cdf0-44e8-9cb4-3b0d95129af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The app keeps crashing, and it’s really frustrating to use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9989112615585327}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence2)\n",
    "sentiment_pipeline(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c40a625-1f71-46cd-8e28-1a461fe08dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific_model=pipeline(\"setiment-analysis\", model=\"______\")\n",
    "#sentiment-analysis is the task, while we can also specify the model if they are trained for certain text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38569d0-8509-4823-bf38-0a4fb4e4829d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117eb31c-21c6-4e8a-8a87-e699fd037d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
